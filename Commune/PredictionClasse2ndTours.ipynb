{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3d35130",
   "metadata": {},
   "source": [
    "# Partie sur la prediction des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc97542",
   "metadata": {},
   "source": [
    "## Classification des elections du second tour 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24567f5",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a296d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4129ba97",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Pandas requires version '3.1.0' or newer of 'openpyxl' (version '3.0.10' currently installed).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#creation du dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Presidentielle 2 tour 2022\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m df_resultatPresidentielle \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../resultats-par-niveau-subcom-t2-france-entiere.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[1;32m      5\u001b[0m df_resultatPresidentielle \u001b[38;5;241m=\u001b[39m df_resultatPresidentielle\u001b[38;5;241m.\u001b[39miloc[:, [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m25\u001b[39m, \u001b[38;5;241m32\u001b[39m]]\n\u001b[1;32m      6\u001b[0m df_resultatPresidentielle\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdep\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAbstentions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMacron\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLepen\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[1;32m    496\u001b[0m         io,\n\u001b[1;32m    497\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    498\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m    499\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[1;32m    500\u001b[0m     )\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_base.py:1567\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m   1565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[0;32m-> 1567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engines[engine](\n\u001b[1;32m   1568\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io,\n\u001b[1;32m   1569\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m   1570\u001b[0m     engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[1;32m   1571\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/excel/_openpyxl.py:552\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    539\u001b[0m     engine_kwargs: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    540\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    541\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;124;03m        Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    554\u001b[0m         filepath_or_buffer,\n\u001b[1;32m    555\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    556\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[1;32m    557\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/compat/_optional.py:164\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Pandas requires version '3.1.0' or newer of 'openpyxl' (version '3.0.10' currently installed)."
     ]
    }
   ],
   "source": [
    "#creation du dataset\n",
    "\n",
    "#Presidentielle 2 tour 2022\n",
    "df_resultatPresidentielle = pd.read_excel('../resultats-par-niveau-subcom-t2-france-entiere.xlsx').dropna()\n",
    "df_resultatPresidentielle = df_resultatPresidentielle.iloc[:, [0,2,7, 25, 32]]\n",
    "df_resultatPresidentielle.columns = ['dep','com', 'Abstentions', 'Macron', 'Lepen']\n",
    "df_resultatPresidentielle['COM'] = df_resultatPresidentielle['dep'].astype(str) + df_resultatPresidentielle['com'].astype(str).str.zfill(3)\n",
    "df_resultatPresidentielle = df_resultatPresidentielle.drop(['dep','com'], axis=1)\n",
    "#print(df_resultatPresidentielle)\n",
    "\n",
    "#election presidentielle 1 tour 2022\n",
    "df_election2022 = pd.read_excel('../AutreDataCommune/resultats-par-niveau-burvot-t1-france-entiere.xlsx').dropna()\n",
    "df_election2022 = df_election2022.iloc[:, [0,4,9, 27, 34, 41, 48, 55, 62, 69, 76, 83, 90, 97, 104]]\n",
    "df_election2022.columns = ['dep','com', 'ABSTENTIONS', 'ARTHAUD', 'ROUSSEL', 'MACRON', 'LASSALLE', 'LEPEN', 'ZEMMOUR', 'MÉLENCHON', 'HIDALGO', 'JADOT', 'PÉCRESSE', 'POUTOU', 'DUPONT-AIGNAN']\n",
    "df_election2022['COM'] = df_election2022['dep'].astype(str) + df_election2022['com'].astype(str).str.zfill(3)\n",
    "df_election2022 = df_election2022.drop(['dep','com'], axis=1)\n",
    "df_election2022 = df_election2022.groupby('COM')[['ABSTENTIONS', 'ARTHAUD', 'ROUSSEL', 'MACRON', 'LASSALLE', 'LEPEN', 'ZEMMOUR', 'MÉLENCHON', 'HIDALGO', 'JADOT', 'PÉCRESSE', 'POUTOU', 'DUPONT-AIGNAN']].mean().reset_index()\n",
    "#print(df_election2022)\n",
    "\n",
    "#Presidentielle 2 tour 2017\n",
    "df_election2017 = pd.read_excel('../AutreDataCommune/Presidentielle_2017_Resultats_Communes_Tour_2_c.xls').dropna()\n",
    "df_election2017 = df_election2017.iloc[1:, [0,2, 6, 24, 31]]\n",
    "df_election2017.columns = ['dep','com','Abstentions17','Macron17', 'Lepen17']\n",
    "df_election2017['COM'] = df_election2017['dep'].astype(str).str.zfill(2) + df_election2017['com'].astype(str).str.zfill(3)\n",
    "df_election2017 = df_election2017.drop(['dep','com'], axis=1)\n",
    "#print(df_election2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Niveau d'etude par sexe \n",
    "df_niveauEtude = pd.read_excel('../AutreDataCommune/diplomesFormation-2020.xlsx', sheet_name='COM_2020')\n",
    "df_niveauEtude = df_niveauEtude.iloc[5:, [0,55,56,57,58,59,60,61,63,64,65,66,67,68,69]].dropna()\n",
    "df_niveauEtude.columns = ['COM','P20_HNSCOL15P_DIPLMIN','P20_HNSCOL15P_BEPC','P20_HNSCOL15P_CAPBEP','P20_HNSCOL15P_BAC','P20_HNSCOL15P_SUP2','P20_HNSCOL15P_SUP34','P20_HNSCOL15P_SUP5','P20_FNSCOL15P_DIPLMIN','P20_FNSCOL15P_BEPC','P20_FNSCOL15P_CAPBEP','P20_FNSCOL15P_BAC','P20_FNSCOL15P_SUP2','P20_FNSCOL15P_SUP34','P20_FNSCOL15P_SUP5']\n",
    "#print(df_niveauEtude)\n",
    "\n",
    "#Proprotion d'imigration\n",
    "df_PopImmigre = pd.read_excel('../AutreDataCommune/ImmigréCommune.xlsx', sheet_name='Data')\n",
    "df_PopImmigre = df_PopImmigre[df_PopImmigre.iloc[:,2] == '2020']\n",
    "df_PopImmigre = df_PopImmigre.iloc[:, [0, 3]]\n",
    "df_PopImmigre.columns = ['COM', 'part_immigres']\n",
    "df_PopImmigre.dropna()\n",
    "#print(df_PopImmigre)\n",
    "\n",
    "#Taux de chomage\n",
    "df_chomeur = pd.read_csv('../AutreDataCommune/DemandeursEmploiInscriparCommunePlus5000hab.csv', skiprows=3, skipfooter=3, delimiter=';').dropna()\n",
    "df_chomeur.columns = ['COM', 'chomeur']\n",
    "df_chomeur['NCOM'] = df_chomeur['COM'].str.extract(r'([a-zA-Zéàêèôâîï\\-_]+)')\n",
    "df_chomeur['COM'] = df_chomeur['COM'].str.extract(r'(\\d+)')\n",
    "df_chomeur = df_chomeur.sort_values(by='COM')\n",
    "df_chomeur['chomeur'] = df_chomeur['chomeur'].str.replace(' ', '')\n",
    "df_chomeur['chomeur'] = df_chomeur['chomeur'].astype(float)\n",
    "#print(df_chomeur)\n",
    "\n",
    "#Tranche d'age\n",
    "df_age = pd.read_excel('../AutreDataCommune/age.xlsx', sheet_name='COM')\n",
    "df_age = df_age.iloc[:, [0,1, 12,13,14,15,16,17,23,24,25,26,27,28]]\n",
    "df_age['COM'] = df_age['COM'].astype(str).str.zfill(5)\n",
    "df_age.dropna()\n",
    "#print(df_age)\n",
    "\n",
    "#crime pour mille habitant\n",
    "df_crime = pd.read_csv('../AutreDataDepartement/crimes_communes_2022.csv', delimiter=';')\n",
    "df_crime = df_crime[df_crime.iloc[:,1] == '2020-01-01']\n",
    "#print(df_crime)\n",
    "\n",
    "#Revenue moyen par commune\n",
    "df_revenue = pd.read_excel('../AutreDataCommune/RevenueCommune2013.xlsx').dropna()\n",
    "df_revenue = df_revenue.iloc[:, [0, 2]]\n",
    "df_revenue.columns = ['COM', 'RevenueCommune']\n",
    "#print(df_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ffc231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nettoyage des données et Fusion: AGE, CRIME et CHOMAGE\n",
    "\n",
    "#Creation du pourcentage par colonne\n",
    "df_age['PopTotal'] = df_age.iloc[:, 2:].sum(axis=1)\n",
    "for colonne in df_age.columns[2:-1]:\n",
    "    df_age[colonne] = df_age[colonne] / df_age['PopTotal'] * 100\n",
    "\n",
    "chomeur_dict = df_chomeur.set_index('NCOM')['chomeur'].to_dict()\n",
    "df_age['chomeur'] = df_age['NCOM'].map(chomeur_dict)\n",
    "\n",
    "#Rajout des données manquante avec le hazard et Creation du pourcentage par colonne\n",
    "for index, row in df_age.iterrows():\n",
    "    if row['chomeur'] * 0.4 > row['PopTotal'] or pd.isnull(row['chomeur']):\n",
    "        df_age.at[index, 'chomeur'] = row['PopTotal'] * (random.uniform(5, 10)/100)\n",
    "df_age['chomeur'] = df_age['chomeur'] / df_age['PopTotal'] * 100\n",
    "\n",
    "#Nettoyage des données et Creation du pourcentage par colonne\n",
    "nouvelle_colonne = df_crime.groupby('code_insee')['tauxpourmille'].sum()\n",
    "df_age['crime'] = df_age['COM'].map(nouvelle_colonne)\n",
    "\n",
    "for index, row in df_age.iterrows():\n",
    "    if pd.isnull(row['crime']):\n",
    "        df_age.at[index, 'crime'] = 0\n",
    "df_age = df_age.drop(columns=['NCOM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combinaison des données\n",
    "\n",
    "df_concat = pd.merge(df_resultatPresidentielle, df_election2022,  on='COM')\n",
    "df_concat = pd.merge(df_concat, df_election2017, on='COM')\n",
    "df_concat = pd.merge(df_concat, df_niveauEtude, on='COM')\n",
    "df_concat = pd.merge(df_concat, df_PopImmigre, on='COM')\n",
    "df_concat = pd.merge(df_concat, df_age, on='COM')\n",
    "df_concat = pd.merge(df_concat, df_revenue, on='COM')\n",
    "\n",
    "#print(df_concat.head())\n",
    "print(df_concat.info())\n",
    "print(df_concat.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e8163",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coherence des données\n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(data=df_concat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0844174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparation des données pour les entrainements\n",
    "\n",
    "# Sélection des features\n",
    "features = df_concat.drop(['COM','Macron', 'Lepen', 'Abstentions'], axis=1)\n",
    "y = [0 if x <= 50 else 1 for x in df_concat['Macron']]\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n",
    "\n",
    "#division des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#definition des labels\n",
    "target_names = ['Lepen', 'Macron']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb692461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6e09540",
   "metadata": {},
   "source": [
    "### Application de SVM, en faisant du copier coller du tp8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942aaf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = SVC(kernel='linear')\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur les données de test et évaluer les performances\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "print(\"Performance du SVM avec un noyau linéaire :\")\n",
    "print(classification_report(y_test, y_pred_linear, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65989fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = SVC(kernel='poly')\n",
    "svm_linear.fit(X_train, y_train)\n",
    "\n",
    "# Prédire sur les données de test et évaluer les performances\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "print(\"Performance du SVM avec un noyau linéaire :\")\n",
    "print(classification_report(y_test, y_pred_linear, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0077c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred_best = best_svm.predict(X_test)\n",
    "print(\"Meilleurs paramètres pour SVM:\", grid_search.best_params_)\n",
    "print(\"Performance du SVM avec les meilleurs paramètres :\")\n",
    "print(classification_report(y_test, y_pred_best, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2dc0ad",
   "metadata": {},
   "source": [
    "### Application de Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9139f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# régression logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logReg = LogisticRegression()\n",
    "logReg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logReg.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaddedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier using Ridge regression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "ridgeClf = RidgeClassifier()\n",
    "ridgeClf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = ridgeClf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daaa51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "#Linear classifiers (SVM, logistic regression, etc.) with SGD training.\n",
    "\n",
    "sgdClf = SGDClassifier()\n",
    "sgdClf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = sgdClf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820b6fc",
   "metadata": {},
   "source": [
    "### Application de Foret aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f80437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Entraînement d'une forêt aléatoire\n",
    "forest_model = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred_forest = forest_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_forest, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390e937f",
   "metadata": {},
   "source": [
    "### Reseau de neuronne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b381e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers, losses, callbacks\n",
    "import numpy as np\n",
    "\n",
    "X_trainNN = np.array(X_train)\n",
    "y_trainNN = np.array(y_train)\n",
    "X_valNN, X_testNN = train_test_split(X_test, test_size=0.5, random_state=42)\n",
    "y_valNN, y_testNN = train_test_split(y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "X_valNN = np.array(X_valNN)\n",
    "y_valNN = np.array(y_valNN)\n",
    "\n",
    "X_testNN = np.array(X_testNN)\n",
    "y_testNN = np.array(y_testNN)\n",
    "\n",
    "CallBackSave = callbacks.ModelCheckpoint(\"best_model_classification.keras\", \n",
    "                                         monitor='val_loss', \n",
    "                                         save_best_only=True, \n",
    "                                         mode='min')\n",
    "\n",
    "callbackStop = callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                  patience=70)\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(features.shape[1], activation='relu'),\n",
    "    tf.keras.layers.Dense(int(features.shape[1]*3/4), activation='relu'),\n",
    "    tf.keras.layers.Dense(int(features.shape[1]/2), activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss=losses.binary_crossentropy,\n",
    "              optimizer=optimizers.Adam(),\n",
    "              metrics=['accuracy'])     \n",
    "\n",
    "history = model.fit(X_trainNN, y_trainNN,\n",
    "                    epochs=1000,validation_data=(X_valNN, y_valNN),\n",
    "                    callbacks=[CallBackSave,callbackStop]\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d334b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(\"best_model_classification.keras\")\n",
    "\n",
    "y_pred_NN = best_model.predict(X_testNN)\n",
    "y_pred_binary = (y_pred_NN > 0.5).astype(int)\n",
    "print(classification_report(y_testNN, y_pred_binary, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = [*range(len(acc))]\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'r')\n",
    "plt.plot(epochs, val_acc, 'b')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = [*range(len(loss))]\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracy per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'r')\n",
    "plt.plot(epochs, val_loss, 'b')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"loss\", \"Validation loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf60f5",
   "metadata": {},
   "source": [
    "### KNN voisin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efec63e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "acc=0\n",
    "bestN_neighbors=1\n",
    "\n",
    "X_valKNN, X_testKNN = train_test_split(X_test, test_size=0.5, random_state=42)\n",
    "y_valKNN, y_testKNN = train_test_split(y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "for i in range (1,X_testKNN.shape[0]+1):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = knn_model.predict(X_valKNN)\n",
    "    matriceConfusion = classification_report(y_valKNN, y_pred, output_dict=True)\n",
    "    \n",
    "    precision_class_0 = matriceConfusion['0']['precision']\n",
    "    precision_class_1 = matriceConfusion['1']['precision']\n",
    "    \n",
    "    avg_precision = (precision_class_0 + precision_class_1) / 2\n",
    "    \n",
    "    if avg_precision > acc:\n",
    "        bestN_neighbors = i\n",
    "        acc = avg_precision\n",
    "        \n",
    "knn_model = KNeighborsClassifier(n_neighbors=bestN_neighbors)\n",
    "knn_model.fit(X_train, y_train)\n",
    "    \n",
    "y_pred = knn_model.predict(X_testKNN)\n",
    "print(classification_report(y_testKNN, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93258fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "rapport = ProfileReport(df_concat)\n",
    "rapport.to_file(\"rapport_corrélations.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71183e35-69ac-433c-a30e-ca1b9a5ddd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
